{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40518fa7-1883-4a41-aab8-280fd7454333",
   "metadata": {},
   "source": [
    "# Content\n",
    "- Pre-processing Test Set\n",
    "    - Imputation missing values\n",
    "    - Categorical Columns Encoding\n",
    "    - Target Encoding\n",
    "    - Scaling\n",
    "    - Drop non-significant features\n",
    "- Predict\n",
    "- Conclusion\n",
    "- Model Summary Breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79274372-8928-4ba8-bbf7-e957b29f83cb",
   "metadata": {},
   "source": [
    "# Pre-processing Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cb6c2f-acbd-4434-bce1-f137c04a95c6",
   "metadata": {},
   "source": [
    "## Imputation missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8489f112-e996-4421-8c6a-b0d961d4161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load your test data\n",
    "test_split = pd.read_csv('test_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "968f55ed-0e6a-46f4-a696-b4171a809713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender             0\n",
      "Ever_Married       0\n",
      "Age                0\n",
      "Graduated          0\n",
      "Profession         0\n",
      "Work_Experience    0\n",
      "Spending_Score     0\n",
      "Family_Size        0\n",
      "Var_1              0\n",
      "Segmentation       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load imputation statistics\n",
    "imputation_stats = pd.read_csv('imputation_stats.csv')\n",
    "imputation_dict = imputation_stats.set_index('Column')['Value'].to_dict()\n",
    "\n",
    "# Redundant ID column removal\n",
    "if 'ID' in test_split.columns:\n",
    "    test_split.drop(columns=['ID'], inplace=True)\n",
    "\n",
    "# Apply imputation statistics to test data\n",
    "for column, value in imputation_dict.items():\n",
    "    if test_split[column].dtype == 'object':\n",
    "        test_split[column].fillna(value, inplace=True)\n",
    "    else:\n",
    "        test_split[column].fillna(float(value), inplace=True)\n",
    "\n",
    "# Confirming imputation\n",
    "print(test_split.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d614a7a-92fd-4607-986f-f2441be07bd7",
   "metadata": {},
   "source": [
    "## Categorical Columns Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "172c7e95-fcf1-4fea-a5de-e70102198868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dziya\\AppData\\Local\\Temp\\ipykernel_23940\\1842504046.py:11: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  test_split[boolean_columns] = test_split[boolean_columns].applymap(int)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding for categorical variables\n",
    "one_hot_columns = ['Gender', 'Profession', 'Ever_Married', 'Graduated', 'Var_1']\n",
    "test_split = pd.get_dummies(test_split, columns=one_hot_columns, drop_first=True)\n",
    "\n",
    "# Ordinal encoding for Spending_Score\n",
    "spending_score_mapping = {'Average': 2, 'High': 1, 'Low': 3}\n",
    "test_split['Spending_Score'] = test_split['Spending_Score'].map(spending_score_mapping)\n",
    "\n",
    "# Convert boolean columns to 0 and 1\n",
    "boolean_columns = [col for col in test_split.columns if test_split[col].dtype == 'bool']\n",
    "test_split[boolean_columns] = test_split[boolean_columns].applymap(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cf7ebe-2648-47ce-9d8d-140e8341fb87",
   "metadata": {},
   "source": [
    "## Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b7aa0a42-543b-4b4d-9097-00d8ff874651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Segmentation_A  Segmentation_B  Segmentation_C  Segmentation_D\n",
      "0               0               0               1               0\n",
      "1               0               1               0               0\n",
      "2               1               0               0               0\n",
      "3               0               0               0               1\n",
      "4               1               0               0               0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dziya\\AppData\\Local\\Temp\\ipykernel_23940\\1324969231.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  test_split[boolean_columns] = test_split[boolean_columns].applymap(int)\n"
     ]
    }
   ],
   "source": [
    "# Apply one-hot encoding to the target column for multi-class classification\n",
    "test_split = pd.get_dummies(test_split, columns=['Segmentation'], drop_first=False)\n",
    "\n",
    "# Convert boolean columns to 0 and 1\n",
    "boolean_columns = [col for col in test_split.columns if test_split[col].dtype == 'bool']\n",
    "test_split[boolean_columns] = test_split[boolean_columns].applymap(int)\n",
    "\n",
    "# Verify the one-hot encoded target variable columns\n",
    "print(test_split[['Segmentation_A', 'Segmentation_B', 'Segmentation_C', 'Segmentation_D']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebec930-cb58-4913-a083-2295bb4ff5f2",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b672aad4-f9a9-4254-8575-591a995cc248",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dziya\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Numerical features to be scaled\n",
    "numerical_features = ['Age', 'Work_Experience', 'Family_Size', 'Spending_Score']\n",
    "\n",
    "# Load the scaler using pickle\n",
    "with open('scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "# Scale the numerical features in the test set\n",
    "test_split[numerical_features] = scaler.transform(test_split[numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a152093-4aa5-455c-bde4-15eba5029b02",
   "metadata": {},
   "source": [
    "## Drop non-significant features ( which are non-significant for all 4 target classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "16d76212-f188-4203-b4b3-2311a22eee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-significant features for all target classes\n",
    "non_significant_features = ['Var_1_Cat_5', 'Var_1_Cat_7']\n",
    "\n",
    "# Drop non-significant features from the DataFrame\n",
    "test_split.drop(non_significant_features, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bf62bd-2a3e-454c-bd04-64df61e2df8f",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1851d212-bedb-4657-8622-122bdde14bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "Test loss: 1.1334367990493774\n",
      "Test accuracy: 0.5022860765457153\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Test Set Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Segmentation_A       0.44      0.48      0.46       381\n",
      "Segmentation_B       0.37      0.26      0.31       371\n",
      "Segmentation_C       0.54      0.51      0.52       370\n",
      "Segmentation_D       0.60      0.74      0.66       409\n",
      "\n",
      "      accuracy                           0.50      1531\n",
      "     macro avg       0.49      0.50      0.49      1531\n",
      "  weighted avg       0.49      0.50      0.49      1531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Separate features and target columns for test data\n",
    "X_test = test_split.drop(['Segmentation_A', 'Segmentation_B', 'Segmentation_C', 'Segmentation_D'], axis=1)\n",
    "y_test = test_split[['Segmentation_A', 'Segmentation_B', 'Segmentation_C', 'Segmentation_D']]\n",
    "\n",
    "# Convert y_test to categorical\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = keras.models.load_model('pretrained_ann_classification_model.keras')\n",
    "print('Model loaded')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_accuracy)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Convert the predicted probabilities to class labels for the test set\n",
    "y_test_pred_labels = np.argmax(y_test_pred, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print the classification report for the test set\n",
    "print(\"Test Set Classification Report\")\n",
    "print(classification_report(y_test_labels, y_test_pred_labels, target_names=['Segmentation_A', 'Segmentation_B', 'Segmentation_C', 'Segmentation_D']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab075ce4-9f48-4797-8ed9-da2e53d3e90b",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3202813d-806e-4412-a319-037c22c5d57e",
   "metadata": {},
   "source": [
    "The results show that the model has a consistent performance between the training, validation, and unseen test datasets, indicating good generalizability. Here are the key points summarized in a table:\n",
    "\n",
    "**Performance Metrics**\n",
    "\n",
    "| Dataset           | Loss    | Accuracy | Precision (Weighted Avg) | Recall (Weighted Avg) | F1-Score (Weighted Avg) |\n",
    "|-------------------|---------|----------|--------------------------|-----------------------|-------------------------|\n",
    "| **Training**      | 1.1058  | 0.5335   | 0.52                     | 0.53                  | 0.52                    |\n",
    "| **Validation**    | 1.1231  | 0.5261   | 0.52                     | 0.53                  | 0.52                    |\n",
    "| **Unseen Test**   | 1.1334  | 0.5023   | 0.49                     | 0.50                  | 0.49                    |\n",
    "\n",
    "Overall, the model maintains similar performance across all datasets, with slightly lower accuracy on the unseen test set. The performance metrics indicate that the model is balanced, though there is room for improvement, especially in the recall and F1-scores for some segments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59e1a7c-b37d-4254-bb49-46efc161b48d",
   "metadata": {},
   "source": [
    "# Model Summary Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9d0d239f-486f-4bb1-ae79-3ad2e20368f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,344\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_24 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m260\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,294</span> (67.56 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,294\u001b[0m (67.56 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,764</span> (22.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,764\u001b[0m (22.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,530</span> (45.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m11,530\u001b[0m (45.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0b84ce-37c3-49c9-a8c7-1571ec9bb0de",
   "metadata": {},
   "source": [
    "##### Model Name\n",
    "- **Model Name**: `\"sequential_12\"` \n",
    "  - This indicates it is a sequential model, where layers are stacked one after another in a linear fashion.\n",
    "\n",
    "##### Layers and Parameters\n",
    "\n",
    "###### Layer 1: Dense (`dense_36`)\n",
    "- **Type**: `Dense`\n",
    "- **Output Shape**: `(None, 64)`\n",
    "  - `None` indicates the batch size, which is not fixed and can vary.\n",
    "  - `64` is the number of neurons in this layer.\n",
    "- **Param #**: `1,344`\n",
    "  - Parameters in a dense layer are calculated as:\n",
    "    - `(input_dim + 1) * output_dim`\n",
    "    - Here, `input_dim` is the number of input features. Assuming `input_dim = 20` (from previous context), the calculation is:\n",
    "    - `(20 + 1) * 64 = 21 * 64 = 1,344`\n",
    "\n",
    "###### Layer 2: Dropout (`dropout_24`)\n",
    "- **Type**: `Dropout`\n",
    "- **Output Shape**: `(None, 64)`\n",
    "  - Same as the previous layer because dropout does not change the shape of the data.\n",
    "- **Param #**: `0`\n",
    "  - Dropout does not have parameters.\n",
    "\n",
    "###### Layer 3: Dense (`dense_37`)\n",
    "- **Type**: `Dense`\n",
    "- **Output Shape**: `(None, 64)`\n",
    "  - `64` neurons, same as the previous dense layer.\n",
    "- **Param #**: `4,160`\n",
    "  - Calculation is similar to the first dense layer but now with `64` inputs from the previous layer:\n",
    "  - `(64 + 1) * 64 = 65 * 64 = 4,160`\n",
    "\n",
    "###### Layer 4: Dropout (`dropout_25`)\n",
    "- **Type**: `Dropout`\n",
    "- **Output Shape**: `(None, 64)`\n",
    "  - Same as the previous layer because dropout does not change the shape of the data.\n",
    "- **Param #**: `0`\n",
    "  - Dropout does not have parameters.\n",
    "\n",
    "###### Layer 5: Dense (`dense_38`)\n",
    "- **Type**: `Dense`\n",
    "- **Output Shape**: `(None, 4)`\n",
    "  - `4` neurons, one for each class in the multiclass classification.\n",
    "- **Param #**: `260`\n",
    "  - Calculation is:\n",
    "  - `(64 + 1) * 4 = 65 * 4 = 260`\n",
    "\n",
    "##### Summary of Parameters\n",
    "- **Total params**: `17,294 (67.56 KB)`\n",
    "  - This includes all parameters in the model (trainable and non-trainable).\n",
    "  - This total seems to be a miscalculation, given the provided individual layer params. The correct total should be `1,344 + 4,160 + 260 = 5,764`.\n",
    "- **Trainable params**: `5,764 (22.52 KB)`\n",
    "  - These are parameters that will be updated during training.\n",
    "- **Non-trainable params**: `0 (0.00 B)`\n",
    "  - There are no non-trainable parameters in this model.\n",
    "\n",
    "##### Optimizer Params\n",
    "- **Optimizer params**: `11,530 (45.04 KB)`\n",
    "  - These are parameters related to the Adam optimizer, including moment estimates and other state variables. The exact number can vary depending on the optimizer configuration and the number of model parameters.\n",
    "\n",
    "##### Key Points\n",
    "- **Output Shape `(None, x)`**: `None` signifies a variable batch size, while `x` is the dimension of the output of the layer.\n",
    "- **Parameter Calculation**: For dense layers, parameters include weights and biases, calculated as `(input_dim + 1) * output_dim`.\n",
    "- **Dropout Layers**: Do not have parameters but help prevent overfitting by randomly setting a fraction of input units to 0 at each update during training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29d2d7-cffe-48d9-88bb-4244a8d16944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23c4002-0189-42c5-b8e8-068b1aab63d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
