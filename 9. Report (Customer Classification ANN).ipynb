{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e20588a1-34b6-493f-a8ac-69e8df71d949",
   "metadata": {},
   "source": [
    "# Content\n",
    "- Get Data\n",
    "- Split Data\n",
    "- Preprocessing\n",
    "    - Clean the Data\n",
    "    - Feature Engineering\n",
    "- Dimensionality Reduction\n",
    "- Model Implementation\n",
    "- Fine-tuning\n",
    "    - Address Overfitting (Regularization, Early Stopping)\n",
    "    - Address Underfitting (RandomizedSearchCV with Keras)\n",
    "    - Further Fine-tuning\n",
    "- Predict on unseen Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9ae89f-db78-4e71-9176-a63dc0ae274e",
   "metadata": {},
   "source": [
    "## 1. Get Data\n",
    "\n",
    "The dataset for this project comes from the [Customer Segmentation Classification](https://www.kaggle.com/datasets/kaushiksuresh147/customer-segmentation) task on Kaggle.\n",
    "In this project, we will implement an ANN to demonstrate its capabilities.\n",
    "\n",
    "**Context**\n",
    "An automobile company has plans to enter new markets with their existing products (P1, P2, P3, P4, and P5). After intensive market research, theyâ€™ve deduced that the behavior of the new market is similar to their existing market.\n",
    "\n",
    "In their existing market, the sales team has classified all customers into 4 segments (A, B, C, D ). Then, they performed segmented outreach and communication for a different segment of customers. This strategy has work e exceptionally well for them. They plan to use the same strategy for the new markets and have identified 2627 new potential customers.\n",
    "\n",
    "You are required to help the manager to predict the right group of the new customers.\n",
    "\n",
    "- **train.csv**: Contains the following columns\n",
    "\n",
    "| Variable         | Definition                                                       |\n",
    "|------------------|------------------------------------------------------------------|\n",
    "| **ID**           | Unique ID                                                        |\n",
    "| **Gender**       | Gender of the customer                                           |\n",
    "| **Ever_Married** | Marital status of the customer                                   |\n",
    "| **Age**          | Age of the customer                                              |\n",
    "| **Graduated**    | Is the customer a graduate?                                      |\n",
    "| **Profession**   | Profession of the customer                                       |\n",
    "| **Work_Experience** | Work Experience in years                                       |\n",
    "| **Spending_Score**  | Spending score of the customer                                  |\n",
    "| **Family_Size**     | Number of family members for the customer (including the customer) |\n",
    "| **Var_1**           | Anonymised Category for the customer                            |\n",
    "| **Segmentation**    | (target) Customer Segment of the customer                       |\n",
    "\n",
    "For more details, refer to the [Customer Segmentation Classification](https://www.kaggle.com/datasets/kaushiksuresh147/customer-segmentation).\n",
    "\n",
    "- **Initial EDA**\n",
    "- The dataset contains **8,068 entries** and **11 columns**.\n",
    "- The 'Segmentation' column shows quite **balanced distribution**\n",
    "- Some features are imbalanced\n",
    "- There are duplicates - they were dropped at the beginning\n",
    "- There are missing values\n",
    "- There are categorical features \n",
    "\n",
    "# 2. Split Data\n",
    "After removing duplicates 7951 rows remained.\n",
    "For a 7951-row dataset, an 80/20 split is generally recommended for training an ANN. This split provides a substantial amount of data for training while still maintaining a reasonable size for the test set to evaluate performance.\n",
    "- The `train_split` dataset contains **6,120 entries** and **11 columns**.\n",
    "- The `test_split` dataset contains **1,531 entries** and **11 columns**.\n",
    "We applied a regular split, but not stratify.\n",
    "After split distributions of imbalanced features in train_split and test_split were compared\n",
    "\n",
    "# 3. Preprocessing\n",
    "## 3.1 Clean the Data\n",
    "This stage includes handling missing values, removing duplicates, and correcting errors.\n",
    "\n",
    "- Imputation of missing values:\n",
    "    - **mode** imputation (Ever_Married, Graduated,  Var_1)\n",
    "    - Imputing with a **constant** value like *Unknown* (Profession)\n",
    "    - **median** imputation (Work_Experience, Family_Size)\n",
    "\n",
    "- Duplicates deletion\n",
    "    - Duplicate rows were just deleted (in the previous step)\n",
    "\n",
    "## 3.2 Feature Engineering\n",
    "This stage includes steps to prepare the structured data for machine learning models. The following transformations were applied:\n",
    "- **Categorical features encoding**:\n",
    "    - **One-hot encoding** will be applied for Gender, Profession, Ever_Married, Graduated as they are nominal variables with distinct categories\n",
    "    - One-hot encoding will be applied for Var_1 (we do not have specific information on what each category in Var_1 represents, so treating them as nominal categories and applying one-hot encoding is the correct approach as well).\n",
    "    - **Ordinary encoding** will be applied for Spending_Score: 'Average'-2, 'High'-1 'Low'-3\n",
    "- **Target Encoding**:\n",
    "    - \"Segmentation\" represents multiple classes without an ordinal relationship, one-hot encoding is preferred.\n",
    "- **Scaling**:\n",
    "    When preparing your data for an ANN, focus on scaling continuous numerical features while keeping one-hot encoded categorical features unchanged since they are already represented appropriately for the model.\n",
    "\n",
    "# 4. Dimensionality Reduction\n",
    "The following was done at this stage:\n",
    "- Low Variance Analysis\n",
    "    - There are no columns with variance below the threshold of 0.01. It indicates that most features have sufficient variability and are likely informative for the model.\n",
    "    - The minimum threshold that would result in at least one low-variance column being identified is 0.02. Columns with the lowest variance are 'Profession_Unknown', 'Var_1_Cat_5'.\n",
    "- Feature Importance using F-Statistics\n",
    "    - Selecting a single target column Segmentation_A for the F-statistics test\n",
    "    - Selecting a single target column Segmentation_B for the F-statistics test\n",
    "    - Selecting a single target column Segmentation_C for the F-statistics test\n",
    "    - Selecting a single target column Segmentation_D for the F-statistics test\n",
    "    - Finding common non-significant features for all 4 target classes\n",
    "\n",
    "*Names of the features that are not statistically significant (p-value >= 0.05) from the F-test results*:\n",
    "- for predicting **Segmentation_A**: 'Gender_Male', 'Profession_Homemaker', 'Profession_Unknown', 'Ever_Married_Yes', 'Graduated_Yes', 'Var_1_Cat_3', 'Var_1_Cat_5', 'Var_1_Cat_7'\n",
    "- for predicting **Segmentation_B**: 'Gender_Male', 'Profession_Doctor', 'Profession_Entertainment', 'Profession_Homemaker', 'Profession_Lawyer', 'Var_1_Cat_2', 'Var_1_Cat_3', 'Var_1_Cat_4', 'Var_1_Cat_5', 'Var_1_Cat_6', 'Var_1_Cat_7'\n",
    "- for predicting **Segmentation_C**: 'Gender_Male', 'Profession_Doctor', 'Profession_Lawyer', 'Profession_Unknown', 'Var_1_Cat_2', 'Var_1_Cat_5', 'Var_1_Cat_7'\n",
    "- for predicting **Segmentation_D**: 'Profession_Doctor', 'Profession_Engineer', 'Var_1_Cat_2', 'Var_1_Cat_5', 'Var_1_Cat_7'\n",
    "\n",
    "*Common non-significant features for all 4 targets:* \n",
    "    - 'Var_1_Cat_5', 'Var_1_Cat_7'\n",
    "In the result, non-significant features (which are non-significant for all 4 target classes) were dropped\n",
    "\n",
    "# 5. Model Implementation\n",
    "The following models were created:\n",
    "- ANN Model Implementation for Classification\n",
    "- Random Forest with the OvR strategy\n",
    "**ANN results**\n",
    "1. **Overfitting**: The training accuracy (0.6242) is higher than the test accuracy (0.5172), and the training loss (0.8782) is lower than the test loss (1.1511). This suggests that the model may be overfitting to the training data, capturing noise and patterns that do not generalize well to the test data.\n",
    "\n",
    "2. **Class Imbalance Impact**:\n",
    "    - **Segmentation_D** has the highest precision, recall, and F1-score in both the training and test sets, suggesting that the model is better at predicting this class.\n",
    "    - **Segmentation_B** has the lowest recall and F1-score in both sets, indicating that the model struggles to correctly identify instances of this class.\n",
    "\n",
    "3. **Model Performance**:\n",
    "    - **Training Performance**: The model has a decent performance on the training set with an accuracy of 62%. The F1-scores for the different classes range from 0.47 to 0.74.\n",
    "    - **Test Performance**: The model's performance drops on the test set with an accuracy of 51.7%. The F1-scores range from 0.38 to 0.63, indicating variability in the model's ability to generalize across different segments.\n",
    "\n",
    "**Random Forest with the OvR strategy results**\n",
    "The result was much worse compared to ANN (the observed issue of very high train accuracy and relatively low test accuracy). It was decided to give up on the model.\n",
    "\n",
    "# 6. Fine-tuning\n",
    "## 6.1 Address Overfitting (Regularization, Early Stopping)\n",
    "Regularization: Regularization techniques such as dropout, L1/L2 regularization to prevent overfitting were implemented.\n",
    "Early Stopping: Early stopping was added during training to halt training once the model's performance on a validation set stops improving.\n",
    "**Conclusion from the Results**\n",
    "\n",
    "**Overview of Metrics**\n",
    "\n",
    "| Metric               | Previous Result | New Result                              |\n",
    "|----------------------|-----------------|-----------------------------------------|\n",
    "| **Training Loss**    | 0.8918          | 1.1601                                  |\n",
    "| **Training Accuracy**| 0.6168          | 0.5076                                  |\n",
    "| **Test Loss**        | 1.1721          | 1.1638                                  |\n",
    "| **Test Accuracy**    | 0.5008          | 0.5229                                  |\n",
    "\n",
    "**Training Set Classification Report (old vs new)**\n",
    "\n",
    "| Segmentation      | Precision (Previous) | Recall (Previous) | F1-Score (Previous) | Support (Previous) | Precision (New) | Recall (New) | F1-Score (New) | Support (New) |\n",
    "|-------------------|----------------------|-------------------|---------------------|--------------------|-----------------|--------------|----------------|---------------|\n",
    "| Segmentation_A    | 0.58                 | 0.54              | 0.56                | 1230               | 0.43            | 0.43         | 0.43           | 1230          |\n",
    "| Segmentation_B    | 0.55                 | 0.47              | 0.51                | 1160               | 0.41            | 0.23         | 0.30           | 1160          |\n",
    "| Segmentation_C    | 0.65                 | 0.59              | 0.62                | 1159               | 0.54            | 0.54         | 0.54           | 1159          |\n",
    "| Segmentation_D    | 0.66                 | 0.84              | 0.74                | 1347               | 0.58            | 0.78         | 0.66           | 1347          |\n",
    "| **Overall Accuracy** |                   |                   | 0.62                | 4896               |                 |              | 0.51           | 4896          |\n",
    "| **Macro Avg**     | 0.61                 | 0.61              | 0.61                | 4896               | 0.49            | 0.50         | 0.48           | 4896          |\n",
    "| **Weighted Avg**  | 0.61                 | 0.62              | 0.61                | 4896               | 0.49            | 0.51         | 0.49           | 4896          |\n",
    "\n",
    "**Test Set Classification Report (old vs new)**\n",
    "\n",
    "| Segmentation      | Precision (Previous) | Recall (Previous) | F1-Score (Previous) | Support (Previous) | Precision (New) | Recall (New) | F1-Score (New) | Support (New) |\n",
    "|-------------------|----------------------|-------------------|---------------------|--------------------|-----------------|--------------|----------------|---------------|\n",
    "| Segmentation_A    | 0.42                 | 0.38              | 0.40                | 309                | 0.46            | 0.45         | 0.45           | 309           |\n",
    "| Segmentation_B    | 0.39                 | 0.34              | 0.36                | 283                | 0.44            | 0.25         | 0.32           | 283           |\n",
    "| Segmentation_C    | 0.59                 | 0.53              | 0.56                | 292                | 0.57            | 0.57         | 0.57           | 292           |\n",
    "| Segmentation_D    | 0.56                 | 0.72              | 0.63                | 340                | 0.57            | 0.78         | 0.66           | 340           |\n",
    "| **Overall Accuracy** |                   |                   | 0.50                | 1224               |                 |              | 0.52           | 1224          |\n",
    "| **Macro Avg**     | 0.49                 | 0.49              | 0.49                | 1224               | 0.51            | 0.51         | 0.50           | 1224          |\n",
    "| **Weighted Avg**  | 0.49                 | 0.50              | 0.49                | 1224               | 0.51            | 0.52         | 0.51           | 1224          |\n",
    "\n",
    "**Key insights**\n",
    "1. *Overfitting Mitigation*: \n",
    "   - The regularization techniques and early stopping appear to have reduced overfitting, as indicated by the more consistent performance between the training and test sets. However, the overall accuracy has decreased, suggesting that the model may now be underfitting.\n",
    "\n",
    "2. *Class Performance*:\n",
    "   - *Segmentation_D*: Maintains relatively high precision, recall, and F1-score, indicating the model's robustness in predicting this class.\n",
    "   - *Segmentation_B*: Shows a drop in recall and F1-score, suggesting that the model still struggles to correctly identify instances of this class.\n",
    "\n",
    "3. *Model Performance*:\n",
    "   - *Training Performance*: The new model shows lower performance on the training set compared to the previous one, indicating the impact of regularization.\n",
    "   - *Test Performance*: The new model's performance on the test set is slightly lower, which might be an indicator of underfitting due to the regularization being too strong or the need for more epochs.\n",
    "\n",
    "## 6.2 Address Underfitting (RandomizedSearchCV with Keras)\n",
    "\n",
    "Search over different dropout rates and L2 regularization strengths added. Early stopping patience changed from 10 to 20.\n",
    "\n",
    "**Training Set Classification Report (old vs new)**\n",
    "\n",
    "| Segmentation  | Precision (Previous) | Recall (Previous) | F1-Score (Previous) | Support (Previous) | Precision (New) | Recall (New) | F1-Score (New) | Support (New) |\n",
    "|---------------|----------------------|-------------------|---------------------|--------------------|-----------------|--------------|----------------|---------------|\n",
    "| Segmentation_A| 0.43                 | 0.43              | 0.43                | 1230               | 0.45            | 0.46         | 0.46           | 1230          |\n",
    "| Segmentation_B| 0.41                 | 0.23              | 0.30                | 1160               | 0.44            | 0.26         | 0.33           | 1160          |\n",
    "| Segmentation_C| 0.54                 | 0.54              | 0.54                | 1159               | 0.57            | 0.53         | 0.55           | 1159          |\n",
    "| Segmentation_D| 0.58                 | 0.78              | 0.66                | 1347               | 0.58            | 0.81         | 0.68           | 1347          |\n",
    "| Accuracy      |                      |                   | 0.51                | 4896               |                 |              | 0.53           | 4896          |\n",
    "| Macro Avg     | 0.49                 | 0.50              | 0.48                | 4896               | 0.51            | 0.52         | 0.50           | 4896          |\n",
    "| Weighted Avg  | 0.49                 | 0.51              | 0.49                | 4896               | 0.51            | 0.53         | 0.51           | 4896          |\n",
    "\n",
    "**Test Set Classification Report (old vs new)**\n",
    "\n",
    "| Segmentation  | Precision (Previous) | Recall (Previous) | F1-Score (Previous) | Support (Previous) | Precision (New) | Recall (New) | F1-Score (New) | Support (New) |\n",
    "|---------------|----------------------|-------------------|---------------------|--------------------|-----------------|--------------|----------------|---------------|\n",
    "| Segmentation_A| 0.46                 | 0.45              | 0.45                | 309                | 0.43            | 0.44         | 0.43           | 309           |\n",
    "| Segmentation_B| 0.44                 | 0.25              | 0.32                | 283                | 0.44            | 0.26         | 0.33           | 283           |\n",
    "| Segmentation_C| 0.57                 | 0.57              | 0.57                | 292                | 0.60            | 0.55         | 0.57           | 292           |\n",
    "| Segmentation_D| 0.57                 | 0.78              | 0.66                | 340                | 0.58            | 0.80         | 0.67           | 340           |\n",
    "| Accuracy      |                      |                   | 0.52                | 1224               |                 |              | 0.52           | 1224          |\n",
    "| Macro Avg     | 0.51                 | 0.51              | 0.50                | 1224               | 0.51            | 0.51         | 0.50           | 1224          |\n",
    "| Weighted Avg  | 0.51                 | 0.52              | 0.51                | 1224               | 0.51            | 0.52         | 0.51           | 1224          |\n",
    "\n",
    "**Overview of Metrics**\n",
    "\n",
    "| Metric               | Previous Result | New Result                              |\n",
    "|----------------------|-----------------|-----------------------------------------|\n",
    "| **Training Loss**    | 1.1601          | 1.1262                                  |\n",
    "| **Training Accuracy**| 0.5076          | 0.5255                                  |\n",
    "| **Test Loss**        | 1.1638          | 1.1389                                  |\n",
    "| **Test Accuracy**    | 0.5229          | 0.5237                                  |\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "- *Training Set*:\n",
    "  - The new model shows a slight improvement in overall accuracy from 0.51 to 0.53.\n",
    "  - Precision, recall, and F1-scores have slightly increased for Segmentation_A and Segmentation_B but decreased slightly for Segmentation_C and Segmentation_D.\n",
    "  - The macro and weighted averages for precision, recall, and F1-score have also improved slightly.\n",
    "\n",
    "- *Test Set*:\n",
    "  - The overall accuracy on the test set increased slightly from 0.52 to 0.53.\n",
    "  - Precision, recall, and F1-scores have increased for Segmentation_C and Segmentation_D but slightly decreased for Segmentation_A and Segmentation_B.\n",
    "  - Macro and weighted averages for precision, recall, and F1-score show slight improvements.\n",
    "\n",
    "The slight improvements in both training and test set metrics indicate that the chosen best hyperparameters (dropout rate and L2 regularization) have positively impacted its performance, making it more generalizable and defying the segments correctly.\n",
    "t more generalizable and better at classifying the segments correctly.\n",
    "\n",
    "       \n",
    "## 6.3. Further Fine-tuning\n",
    "Search over different dropout, L2 reg, activation, epochs, and batch_size. Also, patience in reduce_lr was increased from 5 to 10.\n",
    "\n",
    "**Training Set Classification Report (old vs new)**\n",
    "\n",
    "| Segmentation  | Precision (Previous) | Recall (Previous) | F1-Score (Previous) | Support (Previous) | Precision (New) | Recall (New) | F1-Score (New) | Support (New) |\n",
    "|---------------|----------------------|-------------------|---------------------|--------------------|-----------------|--------------|----------------|---------------|\n",
    "| Segmentation_A| 0.45                 | 0.46              | 0.46                | 1230               | 0.47            | 0.49         | 0.48           | 1230          |\n",
    "| Segmentation_B| 0.44                 | 0.26              | 0.33                | 1160               | 0.44            | 0.32         | 0.37           | 1160          |\n",
    "| Segmentation_C| 0.57                 | 0.53              | 0.55                | 1159               | 0.58            | 0.54         | 0.56           | 1159          |\n",
    "| Segmentation_D| 0.58                 | 0.81              | 0.68                | 1347               | 0.61            | 0.76         | 0.68           | 1347          |\n",
    "| **Accuracy**  |                      |                   | 0.53                | 4896               |                 |              | 0.54           | 4896          |\n",
    "| **Macro Avg** | 0.51                 | 0.52              | 0.50                | 4896               | 0.52            | 0.53         | 0.52           | 4896          |\n",
    "| **Weighted Avg** | 0.51              | 0.53              | 0.51                | 4896               | 0.53            | 0.54         | 0.53           | 4896          |\n",
    "\n",
    "**Test Set Classification Report (old vs new)**\n",
    "\n",
    "| Segmentation  | Precision (Previous) | Recall (Previous) | F1-Score (Previous) | Support (Previous) | Precision (New) | Recall (New) | F1-Score (New) | Support (New) |\n",
    "|---------------|----------------------|-------------------|---------------------|--------------------|-----------------|--------------|----------------|---------------|\n",
    "| Segmentation_A| 0.43                 | 0.44              | 0.43                | 309                | 0.43            | 0.47         | 0.45           | 309           |\n",
    "| Segmentation_B| 0.44                 | 0.26              | 0.33                | 283                | 0.42            | 0.27         | 0.33           | 283           |\n",
    "| Segmentation_C| 0.60                 | 0.55              | 0.57                | 292                | 0.58            | 0.56         | 0.57           | 292           |\n",
    "| Segmentation_D| 0.58                 | 0.80              | 0.67                | 340                | 0.60            | 0.75         | 0.67           | 340           |\n",
    "| **Accuracy**  |                      |                   | 0.52                | 1224               |                 |              | 0.52           | 1224          |\n",
    "| **Macro Avg** | 0.51                 | 0.51              | 0.50                | 1224               | 0.51            | 0.51         | 0.50           | 1224          |\n",
    "| **Weighted Avg** | 0.51              | 0.52              | 0.51                | 1224               | 0.51            | 0.52         | 0.51           | 1224          |\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "- *Training Set*:\n",
    "  - The overall accuracy on the training set has slightly increased from 0.53 to 0.54.\n",
    "  - Precision, recall, and F1-scores have slightly improved for most segments, with Segmentation_A and Segmentation_D showing the most notable improvements.\n",
    "  - The macro and weighted averages for precision, recall, and F1-score have shown slight improvements.\n",
    "\n",
    "- *Test Set*:\n",
    "  - The overall accuracy on the test set has remained stable at 0.52.\n",
    "  - Precision, recall, and F1-scores have remained relatively stable for Segmentation_B, Segmentation_C, and Segmentation_D, with slight improvements in Segmentation_A.\n",
    "  - Macro and weighted averages for precision, recall, and F1-score have remained stable.\n",
    "\n",
    "The new model, with adjusted hyperparameters and learning rate adjustments, has shown a slight improvement in training performance but has maintained with slight improvements in Segmentation_A s\n",
    "\n",
    "**Best parameters are:**\n",
    "- {'model__learning_rate': 0.001, 'model__l2_reg': 0.01, 'model__dropout_rate': 0.2, 'model__activation': 'relu', 'epochs': 100, 'batch_size': 32}\n",
    "- early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "- reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.0001)ficant improvements in performance.\n",
    "\n",
    "# 7. Predict on unseen Data\n",
    "The following steps were done on the data set which we put aside right after dropping duplicates.\n",
    "- Pre-processing Test Set\n",
    "    - Imputation missing values\n",
    "    - Categorical Columns Encoding\n",
    "    - Target Encoding\n",
    "    - Scaling\n",
    "    - Drop non-significant features\n",
    "- Predict\n",
    "- Conclusion\n",
    "\n",
    "**Conclusion:**\n",
    "The results show that the model has a consistent performance between the training, validation, and unseen test datasets, indicating good generalizability. Here are the key points summarized in a table:\n",
    "\n",
    "**Performance Metrics**\n",
    "\n",
    "| Dataset           | Loss    | Accuracy | Precision (Weighted Avg) | Recall (Weighted Avg) | F1-Score (Weighted Avg) |\n",
    "|-------------------|---------|----------|--------------------------|-----------------------|-------------------------|\n",
    "| **Training**      | 1.1058  | 0.5335   | 0.52                     | 0.53                  | 0.52                    |\n",
    "| **Validation**    | 1.1231  | 0.5261   | 0.52                     | 0.53                  | 0.52                    |\n",
    "| **Unseen Test**   | 1.1334  | 0.5023   | 0.49                     | 0.50                  | 0.49                    |\n",
    "\n",
    "Overall, the model maintains similar performance across all datasets, with slightly lower accuracy on the unseen test set. The performance metrics indicate that the model is balanced, though there is room for improvement, especially in the recall and F1-scores for some segments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b30dc7e-f409-4ca0-97ca-806765a7ca59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
